{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms.functional as fn\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from utilities import createAnnotation\n",
    "from model_loader import get_new_model\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from PIL import Image \n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "IMAGESROOTDIR = 'NINCO_OOD_classes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, rootDir):\n",
    "        self.rootDir = rootDir\n",
    "        createAnnotation(self.rootDir)\n",
    "        self.annotation =  pd.read_csv('output.csv')\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_path = self.annotation.iloc[index,0]\n",
    "        image = Image.open(data_path)\n",
    "        label = self.annotation.iloc[index,1]\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# instance of class ImageDataset\n",
    "# contains all 765 images with their respective labels\n",
    "imageDataset = ImageDataset(rootDir=IMAGESROOTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Class which is used to rescale the image to a given size\n",
    "# input: outputSize: int\n",
    "# return: tuple(PIL Image, label)\n",
    "class Rescale:\n",
    "    def __init__(self, outputSize):\n",
    "        self.outputSize = outputSize   \n",
    "        \n",
    "        \n",
    "    def __calculateNewSize(self, size):\n",
    "        initialWidth, initialHeight = size\n",
    "        \n",
    "        \n",
    "        RATIO = initialWidth/self.outputSize\n",
    "        newWidth = self.outputSize\n",
    "        newHeight = initialHeight/RATIO\n",
    "        \n",
    "        return (round(newWidth), round(newHeight))  \n",
    "        \n",
    "    #sample data is a tuple(image, label)\n",
    "    def __call__(self, sampleData):\n",
    "        image, label = sampleData\n",
    "        \n",
    "        size = image.size\n",
    "        \n",
    "        newWidth, newHeight = self.__calculateNewSize(size)\n",
    "        \n",
    "        transformedImage = fn.resize(image, [newHeight, newWidth])\n",
    "        \n",
    "        return transformedImage,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Class which is used to center crop non quadratic images\n",
    "# input: outputSize: int\n",
    "# return: tuple(PIL Image, label)\n",
    "class CenterCrop:\n",
    "    def __init__(self, outputSize):\n",
    "        self.outputSize = outputSize\n",
    "        \n",
    "    # creates a quadratic image\n",
    "    def __call__(self, sampleData):\n",
    "        image, label = sampleData\n",
    "        \n",
    "        width, height = image.size\n",
    "        \n",
    "        if (width != height or width != self.outputSize):\n",
    "            centerCrop = torchvision.transforms.CenterCrop(self.outputSize)\n",
    "\n",
    "            return centerCrop(image), label\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Constants for the size of the images\n",
    "RESCALE = 240\n",
    "CROP = 240\n",
    "# objects for resizing\n",
    "rescale = Rescale(RESCALE)\n",
    "crop = CenterCrop(CROP)\n",
    "composed = T.Compose([rescale, crop])\n",
    "\n",
    "# given an Index returns the transformed Immage\n",
    "# input: Index: int\n",
    "# return: tuple(PIL Image, label)\n",
    "def transform(index):\n",
    "    assert index <= len(imageDataset)\n",
    "    tmp = composed(imageDataset[index])\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# objects for tensor transformation\n",
    "pilToTensor = T.ToTensor()\n",
    "tensorToPil = T.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Class which is used to get the resized images with label\n",
    "# input: datasetLength: int\n",
    "# output:{'image': Tensor, 'label': String}\n",
    "class DataLoader(Dataset):\n",
    "    def __init__(self, datasetLength):\n",
    "        self.datasetLength = datasetLength\n",
    "   \n",
    "    def __getitem__(self, index):\n",
    "        assert (0 < index <= self.datasetLength)\n",
    "        self.index = index\n",
    "        (picture, label) = transform(index)\n",
    "        image = pilToTensor(picture)\n",
    "        image = image.unsqueeze(0)\n",
    "        sample = {'image': image, 'label': label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Amount of random samples \n",
    "BATCHSIZE = 4\n",
    "\n",
    "dataloader = DataLoader(len(imageDataset))\n",
    "\n",
    "'''\n",
    "fucntion creates a random batch of data with a given size\n",
    "Arguments: batchsize:int\n",
    "Return: an array with a dict[image:label] \n",
    "'''\n",
    "def createRandomBatch(batchsize):\n",
    "    assert (0<batchsize <= len(imageDataset))\n",
    "    batch = []\n",
    "    for i in range(batchsize):\n",
    "        index = random.randint(0,len(imageDataset))\n",
    "        sample = dataloader[index]\n",
    "        batch.append(sample)\n",
    "    return batch\n",
    "\n",
    "samples = createRandomBatch(BATCHSIZE)\n",
    "  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]]),\n",
       " 'label': 'Caracal caracal caracal',\n",
       " 'prediction': tensor([[-7.5311e-01, -6.4577e-02, -7.6427e-02, -6.2539e-01, -3.9560e-01,\n",
       "           3.1321e-01, -8.2753e-01, -2.1962e-01, -1.7146e-01, -4.1293e-01,\n",
       "          -1.6400e-01,  3.0450e-01,  3.0539e-01, -2.1273e-01, -5.7976e-01,\n",
       "           5.6816e-01,  1.2365e-01, -6.2234e-01,  2.5836e-02, -7.3161e-01,\n",
       "          -5.8814e-01, -8.6760e-01, -1.6410e-01, -2.7080e-01, -1.8726e-01,\n",
       "          -4.2090e-01, -2.4044e-01, -1.2878e+00, -2.3263e-01, -1.9849e-01,\n",
       "          -7.4943e-01,  1.9334e-01, -4.4825e-01, -1.4824e-01, -2.1698e-01,\n",
       "          -8.6336e-01, -9.2239e-01, -5.7618e-01, -5.2328e-01, -5.4794e-01,\n",
       "           7.2490e-01, -3.8126e-01, -1.4159e+00, -4.3525e-01,  5.6656e-01,\n",
       "          -7.5623e-01,  5.9375e-01, -4.0583e-01, -8.9427e-01, -7.3739e-01,\n",
       "          -9.3419e-01, -5.5812e-01, -2.3052e-01, -8.9776e-01,  2.9359e-02,\n",
       "          -5.3417e-01, -9.5585e-01,  1.2867e-01, -3.3459e-01, -1.4403e-01,\n",
       "           7.7358e-01, -8.6881e-02,  6.4142e-01,  1.1125e-01, -3.4364e-01,\n",
       "          -8.6192e-01, -7.6192e-01,  1.3017e-01,  2.7780e-02,  1.2155e-03,\n",
       "          -1.4323e-01, -6.2406e-01,  1.0295e+00,  4.4894e-01,  4.4488e-01,\n",
       "          -5.1063e-02,  1.2809e-01,  1.0382e+00, -4.2899e-01,  1.8163e-01,\n",
       "          -2.3648e-01,  4.9820e-01, -5.0607e-01, -1.6434e-02, -4.0689e-01,\n",
       "           3.2931e-01, -1.6809e-01, -7.9627e-02, -8.1848e-01, -2.3292e-01,\n",
       "           5.3748e-02, -1.0691e-01,  3.6501e-01,  2.8502e-02, -1.6853e-01,\n",
       "          -6.3615e-01, -2.5003e-01, -8.2782e-01, -1.7818e-01, -6.0000e-01,\n",
       "          -5.1431e-01, -8.8985e-02, -4.2574e-01, -7.2119e-01, -2.5731e-01,\n",
       "          -7.1132e-01, -1.8902e-02,  6.6184e-01, -2.9340e-01,  3.6407e-01,\n",
       "          -6.9231e-02, -4.6564e-01, -1.7069e-01, -5.8190e-02, -3.1076e-01,\n",
       "          -5.7980e-01, -6.8046e-02, -2.2297e-01, -3.6686e-01, -5.2795e-01,\n",
       "          -5.1526e-01, -8.5318e-01, -3.5358e-01, -5.9332e-01, -1.0123e+00,\n",
       "          -4.1487e-01, -3.3071e-01, -3.0501e-01, -3.1081e-01, -4.5270e-02,\n",
       "          -9.6317e-01, -2.7771e-01, -2.6964e-01,  7.4171e-03, -2.7072e-01,\n",
       "           1.6697e-01, -9.0511e-01, -6.5805e-01, -7.5710e-01, -5.1419e-01,\n",
       "          -3.3384e-01, -4.9641e-01, -7.9509e-01, -5.7347e-01,  7.4678e-02,\n",
       "          -7.7455e-02, -2.3954e-01,  2.7324e-01, -4.3190e-01, -1.9064e-01,\n",
       "          -2.5318e-01,  5.4046e-02, -5.6409e-01, -2.8149e-01,  1.2305e-01,\n",
       "           4.4205e-01, -5.2676e-01,  9.4712e-02, -1.5067e-01, -2.9431e-01,\n",
       "          -1.1625e-01, -6.2377e-02,  1.6575e-01, -9.3913e-01, -2.6086e-01,\n",
       "          -9.5335e-01, -2.4175e-02, -6.6853e-01, -6.8446e-01,  5.8017e-01,\n",
       "          -4.8949e-01,  1.2329e-02, -7.5267e-01, -9.6399e-01,  3.8402e-01,\n",
       "          -8.9463e-01, -5.0378e-01, -7.0197e-01,  3.3118e-01, -3.2692e-01,\n",
       "          -7.2708e-01, -4.2770e-01, -1.0725e+00,  3.0767e-01, -7.1013e-01,\n",
       "          -7.6601e-01,  2.3020e-02, -1.0790e+00, -5.5632e-01, -3.1692e-01,\n",
       "          -5.9944e-01, -9.9792e-02, -2.6176e-01,  6.0051e-02, -1.0642e+00,\n",
       "           1.4844e-01, -3.8806e-01, -3.6305e-01, -2.3153e-01, -2.2010e-01,\n",
       "          -5.1953e-02,  2.1164e-01,  5.6285e-02,  1.9782e-01, -2.0039e-01,\n",
       "          -5.0811e-02, -2.2345e-01,  5.3265e-02, -4.1902e-01,  9.5260e-03,\n",
       "          -3.0420e-01, -8.3857e-01,  2.0569e-01, -5.9735e-01, -1.2871e+00,\n",
       "           2.6182e-02, -6.0651e-01,  1.4953e-01, -4.7406e-01, -4.3629e-01,\n",
       "          -8.6792e-01, -8.2283e-01, -1.9427e-02, -1.0934e+00, -2.0457e-01,\n",
       "          -1.6940e-01, -4.4001e-01, -7.1046e-01, -7.0612e-01,  8.8642e-03,\n",
       "           2.6539e-01,  1.1450e-01,  3.6180e-01, -6.2783e-01, -4.3843e-02,\n",
       "          -2.7550e-01, -6.5526e-01, -1.6920e-01, -5.0525e-01, -4.0590e-01,\n",
       "           2.4547e-01, -5.5408e-01, -2.2329e-01,  1.0466e-01, -4.1108e-01,\n",
       "           8.8462e-02, -3.1535e-01, -6.6620e-01, -1.4435e-01, -6.0662e-01,\n",
       "          -2.1400e-01, -2.8593e-01, -5.4908e-01, -2.0465e-01,  7.6146e-01,\n",
       "          -4.2320e-03, -8.9833e-02,  1.7686e-01,  2.1318e-01, -2.9348e-01,\n",
       "           3.7374e-01,  1.0992e-01, -4.5954e-01,  3.5120e-02, -6.4495e-01,\n",
       "           1.0229e-01, -1.1530e+00, -4.7092e-01, -4.0707e-02, -2.2407e-01,\n",
       "          -5.4613e-01,  1.8966e-01, -4.2671e-01, -8.2178e-01, -1.0915e-01,\n",
       "          -2.3562e-01, -6.0344e-01, -4.4467e-01,  2.7863e-01, -2.4055e-01,\n",
       "          -7.8200e-01,  1.6210e-01,  1.3329e-01, -3.8062e-01,  5.0660e-01,\n",
       "          -3.8898e-01, -5.8478e-01, -9.0591e-01, -2.3557e-01, -4.1344e-01,\n",
       "          -2.4984e-01, -2.2785e-01, -4.2975e-01, -4.9390e-01,  2.4318e-02,\n",
       "           6.5109e-01,  3.7228e-01, -4.8608e-01, -1.3022e+00, -7.1614e-01,\n",
       "          -1.1232e+00, -2.7382e-01, -6.0895e-01, -4.8664e-01, -1.1350e+00,\n",
       "          -7.8125e-01,  1.6502e-01, -7.8055e-01,  3.3459e-01, -2.0374e-02,\n",
       "          -4.0228e-01,  7.0233e-01, -2.0319e-01,  1.3840e+00,  7.1956e-01,\n",
       "           1.2424e+00,  9.6250e-01, -9.5539e-01,  7.0538e-01,  1.0864e-01,\n",
       "          -4.7402e-01, -5.6256e-01, -3.4332e-01, -1.2901e-01, -4.4061e-01,\n",
       "          -9.4989e-02, -6.2636e-01, -5.7882e-01, -4.5838e-01,  1.6548e-02,\n",
       "          -6.6114e-01, -2.0808e-01,  1.8531e-02,  2.3700e-02, -4.9738e-01,\n",
       "          -4.3092e-01, -6.1969e-01, -8.0380e-01, -7.3656e-01, -4.3630e-01,\n",
       "          -1.6452e-01, -9.9880e-02, -5.1755e-01, -9.8650e-01, -7.7901e-01,\n",
       "           5.6127e-02, -3.9158e-01, -4.5414e-01, -3.6374e-01, -2.5938e-01,\n",
       "          -3.2427e-01,  3.0765e-01, -5.5312e-01, -1.0687e+00,  5.3601e-01,\n",
       "          -1.6238e-01, -3.5133e-02,  1.6360e-01,  3.8898e-01, -1.4680e+00,\n",
       "          -1.2002e+00, -4.0668e-01,  8.5735e-02, -9.8551e-01, -6.4331e-01,\n",
       "          -5.0361e-01, -2.8561e-01, -4.1686e-01, -3.8680e-01, -4.2269e-01,\n",
       "          -5.7690e-01, -6.8260e-01, -3.0387e-01, -4.2770e-01, -9.4927e-01,\n",
       "          -6.4998e-01, -4.4721e-01, -5.5737e-01, -1.2251e+00, -3.7951e-01,\n",
       "          -4.1875e-01, -2.9582e-01, -1.2462e-01, -4.0071e-01, -7.8270e-01,\n",
       "          -2.0750e-01, -5.9891e-01, -7.2925e-01, -2.9060e-01, -6.2396e-01,\n",
       "           3.3211e-01, -8.3696e-02, -3.2134e-01, -1.1319e-01, -1.8220e-01,\n",
       "          -1.0850e+00, -3.2373e-01, -7.6277e-02,  3.2303e-01, -8.0382e-01,\n",
       "          -1.4830e+00, -3.5416e-01, -2.0101e-01, -4.1148e-01, -4.8075e-01,\n",
       "           3.7386e-01, -8.1123e-01,  2.6938e-01, -5.0100e-01,  2.4789e+00,\n",
       "           3.8761e-01,  1.2121e+00,  1.5987e+00, -7.9300e-01,  6.2090e-01,\n",
       "          -6.0928e-02,  8.9043e-02,  6.0407e-02,  1.6948e+00,  7.6017e-01,\n",
       "          -3.9672e-01,  6.7387e-01, -7.5930e-01, -8.5037e-01,  2.0879e-01,\n",
       "           4.0218e-01,  1.4634e-01, -6.1969e-01, -1.1141e+00,  6.4866e-01,\n",
       "           4.0312e-01, -2.8949e-02, -1.0886e-01, -4.4338e-01,  5.6229e-01,\n",
       "           6.3124e-01,  1.4350e-01,  2.2591e-01, -2.5701e-01, -1.2803e+00,\n",
       "           1.4569e-01, -3.7303e-01,  3.5074e-01, -2.0245e-01, -7.6513e-02,\n",
       "           4.4775e-01,  4.5454e+00,  1.2126e-01, -1.7901e-01, -4.1325e-01,\n",
       "          -5.3456e-01, -3.3812e-01, -8.1800e-01, -1.4222e-01, -9.4422e-01,\n",
       "          -6.0408e-01, -2.4655e-01, -6.5274e-01,  3.0048e-01, -1.6934e-01,\n",
       "           4.2298e-01, -5.8559e-01,  7.6710e-01, -9.2262e-01, -9.0164e-02,\n",
       "           1.4050e-01, -8.4252e-01, -8.5813e-01,  4.7337e-01, -1.6026e+00,\n",
       "           3.0753e-01,  6.8448e-02, -4.7443e-01, -2.9126e-01, -1.0781e-02,\n",
       "           1.3271e+00, -3.7086e-01, -1.1357e-01,  1.0833e+00,  1.9473e-01,\n",
       "           2.0721e+00,  8.2868e-01,  1.9746e+00, -2.7324e-01,  7.4745e-01,\n",
       "           2.2028e+00, -8.1968e-01,  1.4308e+00,  8.2256e-01,  2.8946e+00,\n",
       "           6.1930e-01, -9.8904e-01,  1.2743e+00,  8.0570e-01,  2.3138e-01,\n",
       "          -2.1114e-01, -8.3508e-01,  2.4291e-01,  8.4906e-01,  6.1468e-01,\n",
       "          -1.7175e-01,  1.3044e-01, -1.1200e+00, -1.7598e-01,  8.3321e-01,\n",
       "          -1.0249e+00, -3.2864e-01,  1.2835e+00,  1.0886e+00, -4.9847e-01,\n",
       "          -3.2482e-01, -7.6734e-01, -1.2166e+00, -1.9680e-01, -1.0250e+00,\n",
       "          -1.5082e-01, -5.1053e-01,  3.5608e-01, -4.5752e-01,  9.6110e-01,\n",
       "           6.8276e-01, -9.3305e-01, -8.5593e-01, -3.5299e-01, -7.4856e-01,\n",
       "           4.4730e-01, -1.9356e-01,  1.6222e+00, -2.8861e-01, -3.7195e-01,\n",
       "           3.6753e+00,  4.8250e-01, -1.3713e+00,  4.5639e-01,  2.6015e+00,\n",
       "          -1.0065e+00, -1.6100e-01, -4.3213e-01, -8.2234e-02,  2.2022e+00,\n",
       "          -1.5749e-01, -1.0283e+00,  1.6224e-01, -2.3489e-01, -1.1439e+00,\n",
       "           3.6507e+00, -1.1457e+00, -6.0676e-01,  7.4007e-01,  3.5584e+00,\n",
       "          -8.4321e-01, -6.9754e-02,  2.9373e-01,  1.3687e+00, -8.7412e-01,\n",
       "          -1.5711e-02,  5.8282e+00,  2.6672e-01, -1.9673e-01,  5.9095e-01,\n",
       "           4.7121e-01, -2.5093e-01,  7.1187e-01,  1.2619e+00,  1.5435e-01,\n",
       "           1.3586e-01, -5.8582e-01, -8.5042e-01,  8.6058e-02, -3.4560e-01,\n",
       "          -5.1408e-01,  1.4951e-01, -1.9784e-01, -2.4668e-01,  2.8341e-01,\n",
       "          -3.8520e-01, -8.7659e-01, -1.2224e-01, -3.7139e-01, -8.9027e-01,\n",
       "           3.9115e-01,  3.2652e-01, -6.4775e-01,  8.1174e-02, -9.1563e-01,\n",
       "          -5.4749e-01, -7.4907e-01, -4.8107e-01,  2.2080e+00, -7.6934e-02,\n",
       "           1.4299e+00,  2.0346e+00,  9.4301e-01, -7.7097e-01, -6.9364e-01,\n",
       "          -8.6609e-01, -5.1139e-01, -8.4067e-02,  1.5492e+00,  1.6974e+00,\n",
       "          -2.2883e-01, -3.3556e-01, -7.4330e-01, -3.8483e-01,  6.9081e-01,\n",
       "           2.9926e+00,  6.7431e-01, -8.4038e-01, -2.5162e-03, -7.3850e-01,\n",
       "          -3.1868e-01,  2.9141e-01, -1.2328e-01,  1.6000e-01, -2.0413e-02,\n",
       "          -2.9059e-01,  8.1559e-01, -4.6752e-01, -7.9589e-01,  1.2791e+00,\n",
       "           1.9497e+00,  2.2565e-01, -4.6371e-01, -2.9639e-01, -3.7901e-01,\n",
       "          -4.0433e-01,  7.2219e-01,  9.8473e-01,  3.0331e-01,  5.1266e-01,\n",
       "          -8.6914e-01,  4.3577e-01,  4.0060e+00,  1.2085e-01, -9.2180e-01,\n",
       "           3.8650e-01,  1.0785e+00,  5.7266e-01,  2.3361e-02,  2.8894e-01,\n",
       "           5.1027e-01, -1.0101e+00, -2.5312e-01,  3.2960e-01,  1.0057e-01,\n",
       "          -4.4908e-01, -1.0142e-01, -6.2879e-01,  7.2121e-01, -4.0872e-01,\n",
       "           4.1000e-01,  7.3482e+00, -1.0205e+00, -9.9432e-01,  2.0543e-01,\n",
       "           4.1485e-02, -1.4774e-01,  4.3101e-01, -1.1048e+00, -7.3862e-01,\n",
       "           8.6207e-01, -1.0208e+00,  9.9351e-01,  1.5548e-01,  4.4108e+00,\n",
       "          -5.1161e-01, -2.3045e-01, -1.3171e-03,  1.6714e-01,  2.2485e+00,\n",
       "          -6.5863e-01, -3.6912e-01,  1.2291e-01, -6.8221e-01, -4.4278e-01,\n",
       "           2.5411e-01, -6.7860e-01, -4.5198e-01, -7.9543e-01, -6.0360e-02,\n",
       "          -3.4007e-01,  2.3497e+00, -4.1146e-02, -5.0949e-01, -4.4703e-01,\n",
       "           4.4022e-02, -6.7172e-01, -4.3847e-01,  3.1777e+00, -9.1726e-01,\n",
       "          -8.8097e-02, -3.4828e-01,  1.2155e+00, -4.2161e-01, -5.1562e-01,\n",
       "           5.2155e-02,  8.0015e-01, -6.5779e-01, -1.6320e-01, -3.2001e-01,\n",
       "           4.9916e-01,  6.1888e-01,  3.2848e-01, -5.1634e-01,  1.2569e+00,\n",
       "          -1.0996e-01,  7.4217e-01,  1.6037e+00, -3.5401e-01,  7.5093e-01,\n",
       "          -7.5820e-01,  1.6320e+00, -6.3391e-01,  2.3233e-01, -1.1047e+00,\n",
       "          -1.0396e+00,  1.4729e+00,  5.5492e-02,  2.9178e-01,  5.8009e-02,\n",
       "          -5.5504e-01,  1.2545e+00,  2.7315e+00, -3.1154e-02,  5.3038e-02,\n",
       "          -3.0440e-01, -2.5601e-01,  1.0537e+00,  5.9887e-01, -8.1052e-01,\n",
       "          -1.4769e-01, -4.4501e-01,  1.1365e+00,  1.2790e+00, -3.9126e-01,\n",
       "          -9.5007e-01,  5.2420e-01,  2.5751e-01, -2.7575e-01, -9.0542e-01,\n",
       "          -5.0509e-01,  1.1533e+00,  1.2826e+00,  7.1874e-01,  4.0885e-01,\n",
       "           6.5083e-01, -2.7586e-01,  1.9455e-01,  1.2418e+00,  1.0121e-01,\n",
       "           3.8308e-01,  1.6239e-01,  1.0163e+00,  2.6634e+00,  2.8418e+00,\n",
       "           2.8250e-01,  3.0785e-01, -2.3416e-01,  2.0356e-01,  3.3232e-01,\n",
       "           2.0185e+00,  7.1166e-01, -1.0090e+00, -3.6812e-01, -2.6099e-02,\n",
       "          -2.0352e-02,  3.0613e+00, -6.7281e-02, -5.2825e-01,  1.3120e+00,\n",
       "          -5.0176e-02,  1.9553e+00,  6.9776e-01, -5.0437e-01, -1.0996e+00,\n",
       "          -4.1930e-02,  8.8745e-02,  7.2661e-02, -5.9327e-01, -4.3424e-02,\n",
       "          -5.8633e-01,  3.4783e-01,  4.7418e+00, -5.1446e-01, -2.1477e-01,\n",
       "           5.1087e-01, -2.4399e-01, -7.7651e-01, -1.1695e+00,  2.3813e+00,\n",
       "           5.1304e-01,  4.7612e-01,  3.0826e-01, -1.0586e-02,  2.6431e+00,\n",
       "          -4.2004e-01, -1.1568e+00,  3.4877e-01,  7.7746e-01,  1.7740e+00,\n",
       "           1.3883e-01, -8.2864e-01,  1.1933e-01,  3.1496e-01,  2.7489e-01,\n",
       "           2.1844e-01, -3.7684e-01,  1.1201e+00, -8.3145e-01, -1.2357e+00,\n",
       "           9.6562e-01,  3.1793e+00,  5.9451e-01, -2.4055e-01, -2.0997e-03,\n",
       "           1.1796e+00,  3.2651e-01, -1.4632e-02,  1.3320e+00,  6.3554e-01,\n",
       "          -5.2368e-01,  4.5346e-01, -1.3723e+00, -8.7835e-01, -1.2358e-01,\n",
       "          -4.6257e-01,  1.6266e+00,  6.6913e-01,  8.9827e-01, -2.6330e-01,\n",
       "          -5.0418e-01,  8.1937e-01, -4.3878e-01, -3.2465e-01, -3.2632e-01,\n",
       "          -1.1389e-02,  6.7751e-02, -3.0977e-01, -1.8853e-01,  8.0756e-01,\n",
       "           7.0257e-01, -1.1873e+00,  4.0624e-01, -2.9911e-01,  5.9886e-01,\n",
       "           1.1592e+00,  2.3523e-01, -2.4592e-01,  2.2689e+00, -6.5520e-01,\n",
       "           5.3411e-01,  3.5667e+00,  9.0166e-01,  1.4407e-01,  2.0693e+00,\n",
       "          -6.5781e-01, -9.0128e-01, -2.1484e-01,  6.5231e-01,  8.7335e-01,\n",
       "           5.2960e-01, -8.6625e-01, -1.2418e+00,  1.2270e-02, -6.3143e-01,\n",
       "           2.2557e-01, -9.3318e-01, -4.0132e-01,  2.0374e+00,  2.4439e-01,\n",
       "          -3.2259e-01,  3.8219e-01, -5.1353e-01, -7.5369e-01, -1.0761e+00,\n",
       "           8.9327e-02,  7.1170e-01,  5.9403e-01,  6.0311e-01,  6.9545e-01,\n",
       "           4.8065e-01, -1.8476e-01, -3.6780e-02, -1.3013e-01, -7.1093e-01,\n",
       "          -6.3170e-01,  1.5532e+00, -4.3182e-01, -3.1732e-02, -8.8694e-01,\n",
       "           2.6323e-01, -6.3239e-01,  1.6450e+00,  2.5173e+00,  1.0931e-01,\n",
       "          -1.3252e-01, -1.7980e-01,  4.8887e-02,  5.2714e-01,  6.9882e-01,\n",
       "          -4.2132e-01, -1.2499e+00,  7.7691e-01,  4.0270e-02,  8.5666e+00,\n",
       "           3.2712e+00, -6.7157e-01,  2.7722e-01,  5.5210e-01, -3.8076e-01,\n",
       "          -8.1593e-01,  3.2428e-01,  2.8219e-01, -2.0678e-01,  1.0726e-01,\n",
       "          -9.4130e-02,  1.2089e+00,  3.4687e-01, -9.6488e-02,  1.1291e+00,\n",
       "          -1.7632e-02,  2.5691e+00, -3.2627e-01, -4.7744e-01, -9.8177e-01,\n",
       "          -5.2623e-01, -1.2934e+00, -4.0034e-01, -6.7050e-01, -1.5648e-01,\n",
       "          -2.0801e-01, -4.9187e-01,  4.4493e-01,  6.3722e-02,  8.0901e-01,\n",
       "          -5.0374e-01, -1.0167e-01, -6.0212e-01, -1.5807e-01, -6.0985e-02,\n",
       "           3.2684e-01, -4.0259e-01,  7.1584e-02, -6.0918e-01, -9.6348e-01,\n",
       "          -7.1797e-01,  6.9355e-01, -3.3091e-01,  1.9581e-01, -5.9502e-01,\n",
       "           2.6557e-01, -7.1455e-02, -3.8054e-01, -1.0114e+00, -1.0403e+00,\n",
       "          -4.3433e-01, -7.2304e-01, -5.0470e-01,  6.1261e-01,  1.2556e-02,\n",
       "          -1.1329e-02, -1.0591e+00, -3.1912e-01, -6.0701e-01, -3.3284e-01,\n",
       "          -4.1333e-01, -4.2529e-01, -1.0948e+00,  5.3012e-01, -4.9421e-01,\n",
       "          -6.0989e-02,  1.6341e+00,  1.4735e-01,  3.6876e-01,  3.8786e-01,\n",
       "           3.9640e-01,  4.9562e-01,  8.2123e-01,  7.4866e-01, -1.1292e-01,\n",
       "          -1.7995e-01,  6.9559e-01,  1.0401e-01, -4.9283e-01,  8.5050e-01,\n",
       "           3.8459e-01, -1.9362e-01, -2.8010e-02, -1.1564e+00, -9.3492e-01,\n",
       "          -6.3409e-01, -1.9219e-01, -3.7725e-01,  8.7335e-02, -1.1568e+00,\n",
       "          -8.7036e-01,  2.7083e-01, -2.5554e-01, -7.3055e-01,  2.9750e-01]],\n",
       "        grad_fn=<AddmmBackward0>)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loads pretrained model\n",
    "model = get_new_model(\"convnext_tiny\", not_original=True)\n",
    "\n",
    "\n",
    "'''\n",
    "function feeds the loaded model with data\n",
    "Arguments: list[dict[image:tensor,label:str]]\n",
    "Return: None\n",
    "'''\n",
    "def feedModel(samples):\n",
    "    assert(0<len(samples)<len(imageDataset))\n",
    "    for sample in samples:\n",
    "        image, label = sample['image'], sample['label']\n",
    "        prediction = model(image)\n",
    "        sample[\"prediction\"]=prediction\n",
    "    return samples\n",
    "        \n",
    "        \n",
    "        \n",
    "newSamples = feedModel(samples)\n",
    "newSamples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class which is used to rescale the image to a given size\n",
    "# input: outputSize: int\n",
    "# return: tuple(PIL Image, label)\n",
    "class Rescale:\n",
    "    def __init__(self, outputSize):\n",
    "        self.outputSize = outputSize   \n",
    "        \n",
    "        \n",
    "    def __calculateNewSize(self, size):\n",
    "        initialWidth, initialHeight = size\n",
    "        \n",
    "        \n",
    "        RATIO = initialWidth/self.outputSize\n",
    "        newWidth = self.outputSize\n",
    "        newHeight = initialHeight/RATIO\n",
    "        \n",
    "        return (round(newWidth), round(newHeight))  \n",
    "        \n",
    "    #sample data is a tuple(image, label)\n",
    "    def __call__(self, sampleData):\n",
    "        image, label = sampleData\n",
    "        \n",
    "        size = image.size\n",
    "        \n",
    "        newWidth, newHeight = self.__calculateNewSize(size)\n",
    "        \n",
    "        transformedImage = fn.resize(image, [newHeight, newWidth])\n",
    "        \n",
    "        return transformedImage,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class which is used to center crop non quadratic images\n",
    "# input: outputSize: int\n",
    "# return: tuple(PIL Image, label)\n",
    "class CenterCrop:\n",
    "    def __init__(self, outputSize):\n",
    "        self.outputSize = outputSize\n",
    "        \n",
    "    # creates a quadratic image\n",
    "    def __call__(self, sampleData):\n",
    "        image, label = sampleData\n",
    "        \n",
    "        width, height = image.size\n",
    "        \n",
    "        if (width != height or width != self.outputSize):\n",
    "            centerCrop = torchvision.transforms.CenterCrop(self.outputSize)\n",
    "\n",
    "            return centerCrop(image), label\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for the size of the images\n",
    "RESCALE = 240\n",
    "CROP = 240\n",
    "# objects for resizing\n",
    "rescale = Rescale(RESCALE)\n",
    "crop = CenterCrop(CROP)\n",
    "composed = T.Compose([rescale, crop])\n",
    "\n",
    "# given an Index returns the transformed Immage\n",
    "# input: Index: int\n",
    "# return: tuple(PIL Image, label)\n",
    "def transform(index):\n",
    "    assert index <= len(imageDataset)\n",
    "    tmp = composed(imageDataset[index])\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objects for tensor transformation\n",
    "pilToTensor = T.ToTensor()\n",
    "tensorToPil = T.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class which is used to get the resized images with label\n",
    "# input: datasetLength: int\n",
    "# output:{'image': Tensor, 'label': String}\n",
    "class DataLoader(Dataset):\n",
    "    def __init__(self, datasetLength):\n",
    "        self.datasetLength = datasetLength\n",
    "   \n",
    "    def __getitem__(self, index):\n",
    "        assert (0 < index <= self.datasetLength)\n",
    "        self.index = index\n",
    "        (picture, label) = transform(index)\n",
    "        image = pilToTensor(picture)\n",
    "        image = image.unsqueeze(0)\n",
    "        sample = {'image': image, 'label': label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount of random samples \n",
    "BATCHSIZE = 4\n",
    "\n",
    "dataloader = DataLoader(len(imageDataset))\n",
    "\n",
    "'''\n",
    "fucntion creates a random batch of data with a given size\n",
    "Arguments: batchsize:int\n",
    "Return: list[dict[image:tensor,label:str]]\n",
    "'''\n",
    "def createRandomBatch(batchsize):\n",
    "    assert (0<batchsize <= len(imageDataset))\n",
    "    batch = []\n",
    "    for i in range(batchsize):\n",
    "        index = random.randint(0,len(imageDataset))\n",
    "        sample = dataloader[index]\n",
    "        batch.append(sample)\n",
    "    return batch\n",
    "\n",
    "samples = createRandomBatch(BATCHSIZE)\n",
    "  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads pretrained model\n",
    "model = get_new_model(\"convnext_tiny\", not_original=True)\n",
    "\n",
    "\n",
    "'''\n",
    "function feeds the loaded model with data\n",
    "Arguments: list[dict[image:tensor,label:str]]\n",
    "Return: list[dict[image:tensor,label:str, prediction:tensor]]\n",
    "'''\n",
    "def feedModel(samples):\n",
    "    assert(0<len(samples)<len(imageDataset))\n",
    "    samplesWithPrediction =[]\n",
    "    for sample in samples:\n",
    "        image, label = sample['image'], sample['label']\n",
    "        prediction = model(image)\n",
    "        sample['prediction'] = prediction\n",
    "        samplesWithPrediction.append(sample)\n",
    "    return samplesWithPrediction\n",
    "        \n",
    "samplesWithPrediction = feedModel(samples)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
