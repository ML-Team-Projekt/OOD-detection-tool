{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms.functional as fn\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from utilities import createAnnotation\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGESROOTDIR = 'NINCO_OOD_classes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, rootDir):\n",
    "        self.rootDir = rootDir\n",
    "        createAnnotation(self.rootDir)\n",
    "        self.annotation =  pd.read_csv('output.csv')\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_path = self.annotation.iloc[index,0]\n",
    "        image = Image.open(data_path)\n",
    "        label = self.annotation.iloc[index,1]\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance of class ImageDataset\n",
    "# contains all 765 images with their respective labels\n",
    "imageDataset = ImageDataset(rootDir=IMAGESROOTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class which is used to rescale the image to a given size\n",
    "# input: outputSize: int\n",
    "# return: tuple(PIL Image, label)\n",
    "class Rescale:\n",
    "    def __init__(self, outputSize):\n",
    "        self.outputSize = outputSize   \n",
    "        \n",
    "        \n",
    "    def __calculateNewSize(self, size):\n",
    "        initialWidth, initialHeight = size\n",
    "        \n",
    "        if (initialWidth < initialHeight):\n",
    "            \n",
    "            calcFormat = (1-self.outputSize / initialHeight)\n",
    "            \n",
    "            newWidth = initialWidth * calcFormat\n",
    "            newHeight = self.outputSize\n",
    "        elif (initialWidth > initialHeight):\n",
    "            calcFormat = (1-self.outputSize / initialWidth)\n",
    "            newWidth = self.outputSize \n",
    "            newHeight = initialHeight * calcFormat\n",
    "        else:\n",
    "            newWidth = self.outputSize\n",
    "            newHeight = self.outputSize\n",
    "        return (round(newWidth), round(newHeight))  \n",
    "        \n",
    "    #sample data is a tuple(image, label)\n",
    "    def __call__(self, sampleData):\n",
    "        image, label = sampleData\n",
    "        \n",
    "        size = image.size\n",
    "        \n",
    "        newWidth, newHeight = self.__calculateNewSize(size)\n",
    "        \n",
    "        transformedImage = fn.resize(image, [newWidth, newHeight])\n",
    "        \n",
    "        return transformedImage,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class which is used to center crop non quadratic images\n",
    "# input: outputSize: int\n",
    "# return: tuple(PIL Image, label)\n",
    "class CenterCrop:\n",
    "    def __init__(self, outputSize):\n",
    "        self.outputSize = outputSize\n",
    "        \n",
    "    # creates a quadratic image\n",
    "    def __call__(self, sampleData):\n",
    "        image, label = sampleData\n",
    "        \n",
    "        width, height = image.size\n",
    "        \n",
    "        if (width != height and width != self.outputSize and height != self.outputSize):\n",
    "            centerCrop = torchvision.transforms.CenterCrop(self.outputSize)\n",
    "\n",
    "            return centerCrop(image), label\n",
    "        return image,label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
